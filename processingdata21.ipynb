{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38b5bd4-1a2d-4a7f-a29f-a10c570ac5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\n"
     ]
    }
   ],
   "source": [
    "input = \"Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\"\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1264b1a2-fe77-429f-954e-b78116d850b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWERCSE =  barack obama went as a prime minister of usa in the year of 2015 . pm modi is the prime minister of india.\n",
      "REGULAR EXP1 =  barack obama went as a prime minister of usa in the year of 2025 . pm modi is the prime minister of india.\n",
      "REGULAR EXP2 =  **r*** o**** w*nt *s * pr*** **n*st*r o* us* *n t** y**r o* 2015 . p* *o** *s t** pr*** **n*st*r o* *n***.\n",
      "REGULAR EXP3 =  barack obama went as a prime minister of usa in the year of ---- . pm modi is the prime minister of india.\n"
     ]
    }
   ],
   "source": [
    "#(1)lowercase\n",
    "lowercase = input.lower()\n",
    "print(\"LOWERCSE = \", lowercase)\n",
    "\n",
    "#re\n",
    "#pip install re\n",
    "import re\n",
    "lowercase_re = re.sub('2015', '2025', lowercase)\n",
    "print(\"REGULAR EXP1 = \", lowercase_re)\n",
    "lowercase_re = re.sub('[a-m]', '*', lowercase)\n",
    "print(\"REGULAR EXP2 = \", lowercase_re)\n",
    "lowercase_re = re.sub('\\d', '-', lowercase)\n",
    "print(\"REGULAR EXP3 = \", lowercase_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3c6947-c77a-42db-ace3-5724f86d5bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD TOKENS =  ['Barack', 'Obama', 'went', 'as', 'a', 'prime', 'minister', 'of', 'USA', 'in', 'the', 'year', 'of', '2015', '.', 'PM', 'MODI', 'is', 'the', 'prime', 'minister', 'of', 'INDIA', '.']\n",
      "24\n",
      "SENT TOKENS =  ['Barack Obama went as a prime minister of USA in the year of 2015 .', 'PM MODI is the prime minister of INDIA.']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#(2)Tokenization\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "word_tokens = word_tokenize(input)\n",
    "print(\"WORD TOKENS = \", word_tokens)\n",
    "print(len(word_tokens))\n",
    "sent_tokens = sent_tokenize(input)\n",
    "print(\"SENT TOKENS = \", sent_tokens)\n",
    "print(len(sent_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6421114e-1ee0-4953-8f5d-c82c98bca598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama went prime minister USA year 2015 . PM MODI prime minister INDIA .\n"
     ]
    }
   ],
   "source": [
    "#(3)stopwords Removal\n",
    "from nltk.corpus import stopwords\n",
    "#print(stopwords.fileids())\n",
    "stopwords = set(stopwords.words('english'))\n",
    "#print(\"\\n\", stopwords)\n",
    "\n",
    "tokens_stopwords = []\n",
    "for token in word_tokens:\n",
    "    if token not in stopwords:\n",
    "        tokens_stopwords.append(token)\n",
    "print(' '.join(tokens_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ad1d09-41b9-4466-ab88-daaaee926eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barack', 'obama', 'went', 'prime', 'minist', 'usa', 'year', '2015', '.', 'pm', 'modi', 'prime', 'minist', 'india', '.']\n"
     ]
    }
   ],
   "source": [
    "#Stemmer\n",
    "stemming = []\n",
    "from nltk import PorterStemmer\n",
    "for word in tokens_stopwords:\n",
    "    stemming.append(PorterStemmer().stem(word))\n",
    "print(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1a6b56-6faa-4063-b543-bea025ab4c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama', 'went', 'prime', 'minister', 'USA', 'year', '2015', '.', 'PM', 'MODI', 'prime', 'minister', 'INDIA', '.']\n"
     ]
    }
   ],
   "source": [
    "#Lemmatizer\n",
    "from nltk import WordNetLemmatizer\n",
    "lma = []\n",
    "for word in tokens_stopwords:\n",
    "    lma.append(WordNetLemmatizer().lemmatize(word))\n",
    "print(lma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1454a9a-d4bb-46db-9cb8-82b5b74316fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Barack', 'NNP'), ('Obama', 'NNP'), ('went', 'VBD'), ('as', 'IN'), ('a', 'DT'), ('prime', 'JJ'), ('minister', 'NN'), ('of', 'IN'), ('USA', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('year', 'NN'), ('of', 'IN'), ('2015', 'CD'), ('.', '.'), ('PM', 'NNP'), ('MODI', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('prime', 'JJ'), ('minister', 'NN'), ('of', 'IN'), ('INDIA', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#POS Tags\n",
    "from nltk import pos_tag\n",
    "print(pos_tag(word_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08efc226-0587-40d2-8960-920395da4312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3efdb48f-3e47-4bda-a08f-5227cf51f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c09aae9-b19f-41c9-b26b-a2612e813239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b96667a-4831-4931-a600-8a75504b6246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "680f2978-debc-44bb-8ee9-57f960b93441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b876504-c385-4a10-a5d7-d675cbf4882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da374a1d-767a-41c6-9f5a-e6390dd76ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed7fe18-44bd-46ca-b383-691f5eddef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp313-cp313-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp313-cp313-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\admin\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.7-cp313-cp313-win_amd64.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.9 MB 3.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.3/13.9 MB 3.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.4/13.9 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.9/13.9 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.5/13.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.8/13.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.4/13.9 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.7/13.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.0/13.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.3/13.9 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.4/13.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp313-cp313-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp313-cp313-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp313-cp313-win_amd64.whl (115 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl (630 kB)\n",
      "   ---------------------------------------- 0.0/630.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 630.6/630.6 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.6-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.3/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading blis-1.3.0-cp313-cp313-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.9/6.3 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.4 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.9/5.4 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.4 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp313-cp313-win_amd64.whl (149 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "\n",
      "   ---- -----------------------------------  2/18 [spacy-loggers]\n",
      "   -------- -------------------------------  4/18 [smart-open]\n",
      "   --------------- ------------------------  7/18 [cloudpathlib]\n",
      "   ----------------- ----------------------  8/18 [catalogue]\n",
      "   -------------------- -------------------  9/18 [blis]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   ---------------------- ----------------- 10/18 [srsly]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   -------------------------- ------------- 12/18 [language-data]\n",
      "   ---------------------------- ----------- 13/18 [langcodes]\n",
      "   --------------------------------- ------ 15/18 [weasel]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ----------------------------------- ---- 16/18 [thinc]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ------------------------------------- -- 17/18 [spacy]\n",
      "   ---------------------------------------- 18/18 [spacy]\n",
      "\n",
      "Successfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 preshed-3.0.10 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2cf13ab-4d32-45d1-a5ea-a16dcdcc51c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 2.6 MB/s eta 0:00:05\n",
      "     ------ --------------------------------- 2.1/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 2.4/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     --------- ------------------------------ 2.9/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ------------ --------------------------- 3.9/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ------------- -------------------------- 4.5/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.0/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.8/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 8.7/12.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c89166-e26e-496e-b342-4cb3bd9247c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack', 'Obama', 'USA', 'INDIA']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk, sent_tokenize\n",
    "\n",
    "input = \"Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\"\n",
    "ner = ne_chunk(pos_tag(word_tokenize(input)))\n",
    "# print(ner)\n",
    "\n",
    "from nltk.tree import Tree\n",
    "named_entity = []\n",
    "for subtree in ner:\n",
    "    if isinstance(subtree, Tree):\n",
    "        entity = \"\".join([token for token, pos in subtree.leaves()])\n",
    "        named_entity.append(entity)\n",
    "print(named_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfcc1dc-dbc4-45dc-97d4-b1a31414b2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barack Obama', 'USA', 'the year of 2015', 'PM MODI', 'INDIA']\n"
     ]
    }
   ],
   "source": [
    "#pip install spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"Barack Obama went as a prime minister of USA in the year of 2015 . PM MODI is the prime minister of INDIA.\"\n",
    "doc = nlp(text)\n",
    "named_entity = []\n",
    "for ent in doc.ents:\n",
    "    named_entity.append(ent.text)\n",
    "print(named_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af253e0-0a7b-48de-b0c8-a3915c03020f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
